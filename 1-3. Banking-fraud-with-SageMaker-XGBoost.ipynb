{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Training with Amazon SageMaker Built-in XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites](#Prerequisites)\n",
    "3. [Train a model using SageMaker XGBoost](#Train-a-model-using-SageMaker-XGBoost)\n",
    "4. [Set up hosting for the model](#Set-up-hosting-for-the-model)\n",
    "5. [Perform Inference](#Perform-Inference)\n",
    "6. [Stop/Close the Endpoint](#Stop-/-Close-the-Endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "SageMaker의 관리형, 분산 학습 프레임워크를 이용하여 학습할 수 있도록 built-in xgboost 모델을 시작해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "### Import libraries\n",
    "\n",
    "Notebook을 진행하기 위해 여러 라이브러리를 다운로드 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                         # For manipulating filepath names  \n",
    "import sys                                        # For writing outputs to notebook\n",
    "import math                                       # For ceiling function\n",
    "import json                                       # For parsing hosting outputs\n",
    "\n",
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
    "\n",
    "import sagemaker                                  # Amazon SageMaker's Python SDK provides many helper functions\n",
    "from sagemaker import get_execution_role          # Define IAM role\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset\n",
    "\n",
    "위의 셀에서 설정한 S3 bucket 위치에서 데이터를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 19)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./banking_fraud_final_dataset.csv')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>CASH_IN</th>\n",
       "      <th>CASH_OUT</th>\n",
       "      <th>DEBIT</th>\n",
       "      <th>PAYMENT</th>\n",
       "      <th>TRANSFER</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>140421.18</td>\n",
       "      <td>C1667570766</td>\n",
       "      <td>16004.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C2102410298</td>\n",
       "      <td>0.00</td>\n",
       "      <td>140421.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014042</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>216666.53</td>\n",
       "      <td>C1495945377</td>\n",
       "      <td>50398.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C814408370</td>\n",
       "      <td>10119297.16</td>\n",
       "      <td>10335963.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096030</td>\n",
       "      <td>0.098211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>234636.20</td>\n",
       "      <td>C269129885</td>\n",
       "      <td>74262.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1389815469</td>\n",
       "      <td>166046.48</td>\n",
       "      <td>400682.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.003807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>52816.29</td>\n",
       "      <td>C129678616</td>\n",
       "      <td>117751.0</td>\n",
       "      <td>170567.29</td>\n",
       "      <td>C842027837</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>63871.25</td>\n",
       "      <td>C1282823885</td>\n",
       "      <td>6012.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1236511065</td>\n",
       "      <td>456488.36</td>\n",
       "      <td>520359.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006387</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004332</td>\n",
       "      <td>0.004944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type     amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0  CASH_OUT  140421.18  C1667570766        16004.0            0.00   \n",
       "1  CASH_OUT  216666.53  C1495945377        50398.0            0.00   \n",
       "2  CASH_OUT  234636.20   C269129885        74262.0            0.00   \n",
       "3   CASH_IN   52816.29   C129678616       117751.0       170567.29   \n",
       "4  CASH_OUT   63871.25  C1282823885         6012.0            0.00   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  CASH_IN  CASH_OUT  \\\n",
       "0  C2102410298            0.00       140421.18        0        0         1   \n",
       "1   C814408370     10119297.16     10335963.70        0        0         1   \n",
       "2  C1389815469       166046.48       400682.68        0        0         1   \n",
       "3   C842027837            0.00            0.00        0        1         0   \n",
       "4  C1236511065       456488.36       520359.60        0        0         1   \n",
       "\n",
       "   DEBIT  PAYMENT  TRANSFER         0         1         2         3         4  \n",
       "0      0        0         0  0.014042  0.000279  0.000000  0.000000  0.001334  \n",
       "1      0        0         0  0.021667  0.000879  0.000000  0.096030  0.098211  \n",
       "2      0        0         0  0.023464  0.001296  0.000000  0.001576  0.003807  \n",
       "3      0        0         0  0.005282  0.002054  0.003605  0.000000  0.000000  \n",
       "4      0        0         0  0.006387  0.000105  0.000000  0.004332  0.004944  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset\n",
    "\n",
    "데이터를 train | validation | test 데이터셋으로 분리한 후 모델을 훈련합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련에 필요없는 column을 삭제합니다\n",
    "columns_to_drop = ['type', 'isFraud', 'nameOrig', 'nameDest']\n",
    "target = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 train, validation, test 각각 7:2:1의 비율로 나눕니다\n",
    "train_data, validation_data, test_data = np.split(df.sample(frac=1, random_state=2021), [int(0.7 * len(df)), int(0.9 * len(df))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker의 XGBoost 컨테이너는 libSVM 또는 CSV 포맷의 데이터를 사용합니다. 본 예제에서는 CSV를 이용합니다. CSV파일에서 첫번째 컬럼을 타겟변수 값으로 지정해야 하고, 헤더를 포함하고 있지 않아야 합니다. 본 예제에서는 데이터를 train | validation | test 데이터셋으로 분리한 후 작업합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 데이터셋을 노트북 로컬 환경에 저장합니다\n",
    "pd.concat([train_data[target], train_data.drop(columns_to_drop, axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "pd.concat([validation_data[target], validation_data.drop(columns_to_drop, axis=1)], axis=1).to_csv('validation.csv', index=False, header=False)\n",
    "pd.concat([test_data[target], test_data.drop(columns_to_drop, axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "pd.concat([test_data.drop(columns_to_drop, axis=1)], axis=1).to_csv('test_features.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker의 관리형 학습환경에서 이 데이터에 접근할 수 있도록 파일을 S3에 업로드 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket\n",
    "%store -r prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/test_features.csv')).upload_file('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model using SageMaker XGBoost\n",
    "\n",
    "SageMaker 의 ECR 컨테이너를 통해 해당되는 built-in 알고리즘을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "container = sagemaker.image_uris.retrieve(framework = 'xgboost', \n",
    "                                          region = boto3.Session().region_name, \n",
    "                                          version = 'latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV 파일 포맷을 사용하므로 S3의 파일 위치를 알려주는 s3_input 오브젝트를 생성하고 콘텐츠 타입을 CSV로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 파라미터를 지정하여 esitmator를 생성합니다.\n",
    "\n",
    "- xgboost 알고리즘 컨테이너 사용\n",
    "- 사용할 IAM 역할(role)\n",
    "- 학습용 인스턴스 타입과 수량 ('local_cpu'를 사용해 해당 노트북의 인스턴스 내에서 학습을 진행할 수도 있습니다.)\n",
    "- 출력 데이터를 위한 S3위치\n",
    "- 알고리즘 하이퍼파라미터\n",
    "\n",
    "이제 다음 파라미터를 이용하여 .fit() 명령을 실행합니다.\n",
    "- 학습용(train)/검증용(validation) 데이터가 있는 S3 위치\n",
    "\n",
    "본 예제는 학습과 검증 데이터셋을 모두 사용하므로 두 채널을 모두 지정합니다. Trainin job을 수행하기 위해서 학습용 서버가 생성되는데에 5분정도 소요됩니다.\n",
    "\n",
    "데이터 학습을 수행할 시에 발생하는 과금은, EC2 인스턴스의 생성 시간이 제외된 데이터를 학습하는 시간만 요금이 부과됩니다. Log의 마지막 부분에 표시되는 Training seconds와 Billable seconds를 참고하셔서 과금이 발생한 시간을 참고하실 수 있습니다.\n",
    "- Training seconds: Training job을 실행한 실제 컴퓨팅 학습 시간\n",
    "- Billable seconds: Spot 할인이 적용된 후 청구되는 시간\n",
    "\n",
    "---\n",
    "### 아래 값을 변경해주세요.\n",
    "\n",
    "Training estimator에 사용되는 instance count와 instance type을 설정합니다. \n",
    "\n",
    "본 예제 데이터는 크기가 작기에 instance count는 1로 고정합니다.\n",
    "\n",
    "Instance type에는 표준 인스턴스 타입 중 하나인 **ml.m5.xlarge**를 사용합니다. 더 많은 인스턴스 타입은 [여기](https://aws.amazon.com/ko/sagemaker/pricing/)에서 확인할 수 있습니다.\n",
    "\n",
    "추가적으로 Hyperparameters의 값을 조정하며 결과를 비교합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-10 07:07:46 Starting - Starting the training job...\n",
      "2022-04-10 07:08:12 Starting - Preparing the instances for trainingProfilerReport-1649574466: InProgress\n",
      ".........\n",
      "2022-04-10 07:09:38 Downloading - Downloading input data\n",
      "2022-04-10 07:09:38 Training - Downloading the training image.....\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2022-04-10:07:10:27:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2022-04-10:07:10:27:INFO] File size need to be processed in the node: 0.31mb. Available memory size in the node: 8153.15mb\u001b[0m\n",
      "\u001b[34m[2022-04-10:07:10:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[07:10:27] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[07:10:27] 2100x15 matrix with 31500 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2022-04-10:07:10:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[07:10:27] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[07:10:27] 600x15 matrix with 9000 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[07:10:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.030476#011validation-error:0.028333\u001b[0m\n",
      "\u001b[34m[07:10:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.022381#011validation-error:0.026667\u001b[0m\n",
      "\u001b[34m[07:10:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.022381#011validation-error:0.026667\u001b[0m\n",
      "\u001b[34m[07:10:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.018571#011validation-error:0.025\u001b[0m\n",
      "\u001b[34m[07:10:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.018571#011validation-error:0.025\u001b[0m\n",
      "\n",
      "2022-04-10 07:10:45 Uploading - Uploading generated training model\n",
      "2022-04-10 07:10:45 Completed - Training job completed\n",
      "Training seconds: 87\n",
      "Billable seconds: 87\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "job_name='banking-fraud-'+strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='PUT INSTANCE TYPE',           # ml.m5.xlarge\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess,\n",
    "                                    base_job_name=job_name)\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=5)\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hosting for the model\n",
    "### Create endpoint\n",
    "\n",
    "입력 데이터에 대해 xgboost 모델의 학습이 완료되면 이 모델을 실시간 추론을 위한 엔드포인트로 배포합니다. Endpoint 생성은 5-10분 정도 소요됩니다.\n",
    "\n",
    "---\n",
    "### 아래 값을 변경해주세요.\n",
    "\n",
    "모델 배포 및 호스팅에 사용되는 instance type을 설정합니다. \n",
    "\n",
    "표준 인스턴스 타입 중 하나인 **ml.m5.xlarge**를 사용합니다. 더 많은 인스턴스 타입은 [여기](https://aws.amazon.com/ko/sagemaker/pricing/)에서 확인할 수 있습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!CPU times: user 97 ms, sys: 8.4 ms, total: 105 ms\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint_name='banking-fraud-'+strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                           instance_type='PUT INSTANCE TYPE',           # ml.m5.xlarge\n",
    "                           endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Inference\n",
    "### Make predictions using the endpoint\n",
    "\n",
    "머신러닝 모델의 성능을 확인하기 위해 실제값과 예측값을 비교합니다. 추론용 데이터를 엔드포인트에 전달하고 결과를 받아옵니다. 데이터를 HTTP POST request로 보내기 위해 CSV 형태로 직렬화(serialize)하고 결과로 리턴되는 CSV를 디코딩합니다.\n",
    "\n",
    "주의: SageMaker XGBoost에서 CSV포맷으로 추론할 때 요청 데이터는 타겟속성 컬럼을 포함하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "xgb_predictor.serializer = CSVSerializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "엔드포인트를 호출하는 함수를 생성합니다.\n",
    "\n",
    "- 테스트 데이터셋을 반복 (Loop)\n",
    "- rows 만큼 미니매치로 나누기\n",
    "- 미니배치를 CSV string payloads로 변환 (타겟속성 변수 제거)\n",
    "- XGBoost 엔드포인트를 호출하고 예측값 수신\n",
    "- CSV 결과로 리턴된 예측값을 다시 NumPy 배열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 1 completed\n"
     ]
    }
   ],
   "source": [
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for i, array in enumerate(split_array):\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "        if i % 10 == 0:\n",
    "            print(i, 'out of', len(split_array), 'completed')\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "predictions = predict(test_data.drop(columns_to_drop, axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       265\n",
      "           1       0.91      0.86      0.88        35\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.95      0.92      0.93       300\n",
      "weighted avg       0.97      0.97      0.97       300\n",
      "\n",
      "Test accuracy: 0.9733333333333334\n",
      "ROC_AUC score: 0.922911051212938\n"
     ]
    }
   ],
   "source": [
    "# F1-score, accurancy, ROC 값을 확인합니다\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score # import classification metrics\n",
    "\n",
    "print(classification_report(test_data[target], np.round(predictions)))\n",
    "print(\"Test accuracy:\", accuracy_score(test_data[target], np.round(predictions)))\n",
    "print(\"ROC_AUC score:\", roc_auc_score(test_data[target], np.round(predictions) / 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측결과와 실제값을 비교하는 Confusion matrix를 생성합니다. 알고리즘의 샘플링과정에서 랜덤요소가 반영되므로 결과의 숫자는 위 결과와 정확히 동일하지 않을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions  0.0  1.0\n",
       "actuals              \n",
       "0            262    3\n",
       "1              5   30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=test_data['isFraud'], columns=np.round(predictions), rownames=['actuals'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP, TN, FP, FN 은 다음과 같이 정의 되어 있습니다.\n",
    "\n",
    "- TP = Truly (identified as) Positive\n",
    "- TN = Truly (identified as) Negative\n",
    "- FP = Falsely (identified as) Positive\n",
    "- FN = Falsely (identified as) Negative\n",
    "\n",
    "위의 테이블의 각 셀에 해당하는 것을 표시하였습니다.\n",
    "\n",
    "| actuals\\predictions | 0 | 1 |\n",
    "| --- | --- | --- |\n",
    "| 0 | TN | FP |\n",
    "| 1 | FN | TP |\n",
    "\n",
    "\n",
    "이를 바탕으로 Accuracy, Precision, Recall 을 측정할 수 있습니다.\n",
    "- Accuracy = (TP + TN) / (TP + FP + FN + TP)\n",
    "- Precision = TP / (TP + FP) = 670 / (670 + 29)\n",
    "- Recall = TP / (TP + FN) = 670 / (670 + 157)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop / Close the Endpoint\n",
    "\n",
    "본 예제를 모두 마무리한 후 아래 셀을 실행합니다. 다음 명령은 추론 단계에서 생성한 SageMaker에서 호스팅되고 있는 엔드포인트를 제거합니다. 엔드포인트를 삭제하지 않으면 계속 사용요금이 발생할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint is deleted!\n"
     ]
    }
   ],
   "source": [
    "# xgb_predictor.delete_endpoint()\n",
    "print(\"Endpoint is deleted!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
